{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5918599f-4434-4a18-aaa0-3f77b76fd3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Performing Data Search...\n",
      "\n",
      "  -> Searching for PACE_CHL (PACE_OCI_L3M_CHL_V3) from 2023-01-01 to 2025-12-31...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown key keywords",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     keywords \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 56\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mearthaccess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshort_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshort_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemporal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSTART_DATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEND_DATE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounding_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBOUNDING_BOX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloud_hosted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     62\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m     ✅ Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m granules for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmission_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\sharkenv\\lib\\site-packages\\earthaccess\\api.py:135\u001b[0m, in \u001b[0;36msearch_data\u001b[1;34m(count, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Search dataset granules using NASA's CMR.\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m[https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html](https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m earthaccess\u001b[38;5;241m.\u001b[39m__auth__\u001b[38;5;241m.\u001b[39mauthenticated:\n\u001b[1;32m--> 135\u001b[0m     query \u001b[38;5;241m=\u001b[39m DataGranules(earthaccess\u001b[38;5;241m.\u001b[39m__auth__)\u001b[38;5;241m.\u001b[39mparameters(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     query \u001b[38;5;241m=\u001b[39m DataGranules()\u001b[38;5;241m.\u001b[39mparameters(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\sharkenv\\lib\\site-packages\\earthaccess\\search.py:527\u001b[0m, in \u001b[0;36mDataGranules.parameters\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;66;03m# verify the key matches one of our methods\u001b[39;00m\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m methods:\n\u001b[1;32m--> 527\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown key \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key))\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# call the method\u001b[39;00m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown key keywords"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "# --- 1. Define Search Parameters ---\n",
    "\n",
    "# Set a flexible time range. \n",
    "# MODIS/SWOT cover 2023+. PACE data is only available from March 2024 onwards.\n",
    "START_DATE = \"2023-01-01T00:00:00Z\" # Keeps the full 3-year window for MODIS/SWOT\n",
    "END_DATE = \"2025-12-31T23:59:59Z\"\n",
    "\n",
    "# !!! IMPORTANT: VERIFY AND ADJUST YOUR AREA OF INTEREST (AOI) !!!\n",
    "# Example: Western Atlantic/Gulf Stream (-85 W to -50 W, 20 N to 45 N)\n",
    "BOUNDING_BOX = (-85.0, 20.0, -50.0, 45.0)\n",
    "\n",
    "DOWNLOAD_DIR = \"nasa_shark_data_revised_2\"\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- 2. Define REVISED NASA Data Collections (Short Names) ---\n",
    "\n",
    "DATA_COLLECTIONS = {\n",
    "    # *** RECOVERY MISSION 1: PACE (Chlorophyll & NPP) ***\n",
    "    # PACE L3/L4 products start availability in March 2024. \n",
    "    # We will search the full time window; the CMR will only return 2024+ files.\n",
    "    \"PACE_CHL\": \"PACE_OCI_L3M_CHL_V3\",  # High-res, new sensor\n",
    "    \"PACE_NPP\": \"PACE_OCI_L4_NPP_V1\",    # Level 4 data product\n",
    "    \n",
    "    # *** RECOVERY MISSION 2: MODIS-Aqua (Historical Chlorophyll) ***\n",
    "    # The short name 'MODISA_L3m_CHL_4km_MONTHLY' is sometimes rejected.\n",
    "    # We use the generic collection name and constrain to monthly, mapped, and 4km,\n",
    "    # or a known working name if possible. We will try a different standard L3 name.\n",
    "    \"MODIS_CHL\": \"MODISA_L3m_CHL\", # Generic L3 mapped Chlorophyll short name\n",
    "\n",
    "    # Data already found: SWOT and SST (Keep these names)\n",
    "    \"SWOT_SSH\": \"SWOT_L2_LR_SSH_EXPERT_2.0\", \n",
    "    \"SST\": \"MUR-JPL-L4-GLOB-v4.1\" \n",
    "}\n",
    "\n",
    "\n",
    "# --- 3. Run Search and Download for ALL MISSIONS (including successful ones) ---\n",
    "\n",
    "print(\"Step 2: Performing Data Search...\")\n",
    "\n",
    "all_results = []\n",
    "for mission_name, short_name in DATA_COLLECTIONS.items():\n",
    "    print(f\"\\n  -> Searching for {mission_name} ({short_name}) from {START_DATE.split('T')[0]} to {END_DATE.split('T')[0]}...\")\n",
    "\n",
    "    # Search the Common Metadata Repository (CMR)\n",
    "    # We add a constraint for Chlorophyll products to ensure monthly 4km resolution\n",
    "    if mission_name == \"MODIS_CHL\":\n",
    "        # Additional keywords to force monthly 4km selection for the MODIS generic collection\n",
    "        keywords = [\"Monthly\", \"4km\"]\n",
    "    else:\n",
    "        keywords = []\n",
    "\n",
    "    results = earthaccess.search_data(\n",
    "        short_name=short_name,\n",
    "        temporal=(START_DATE, END_DATE),\n",
    "        bounding_box=BOUNDING_BOX,\n",
    "        keywords=keywords,\n",
    "        cloud_hosted=True\n",
    "    )\n",
    "    \n",
    "    if results:\n",
    "        print(f\"     ✅ Found {len(results)} granules for {mission_name}.\")\n",
    "        all_results.extend(results)\n",
    "    else:\n",
    "        print(f\"     ❌ FAILED: Found 0 granules for {mission_name}. Please verify product name and AOI.\")\n",
    "\n",
    "\n",
    "print(f\"\\nStep 3: Initiating bulk download of {len(all_results)} total files...\")\n",
    "if all_results:\n",
    "    # This downloads all files to subfolders within the DOWNLOAD_DIR\n",
    "    earthaccess.download(all_results, DOWNLOAD_DIR)\n",
    "    print(f\"\\n✅ Download complete! All data saved to the '{DOWNLOAD_DIR}' folder.\")\n",
    "else:\n",
    "    print(\"❌ No data found with the current parameters. Download skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffad45c9-8f44-458c-b847-40627c2a767a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\sharkenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Earthdata Login username:  devanandhpr\n",
      "Enter your Earthdata password:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "import earthaccess\n",
    "\n",
    "# Step 1: Login using your Earthdata credentials\n",
    "\n",
    "earthaccess.login()\n",
    "\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6848308-7883-45d9-8dcf-8915f102eaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\sharkenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Performing Comprehensive Data Search (Excluding 'keywords' argument)...\n",
      "\n",
      "  -> Searching for PACE_CHL_NRT (PACE_OCI_L3M_CHL_NRT)...\n",
      "     ✅ Found 190 granules for PACE_CHL_NRT!\n",
      "\n",
      "  -> Searching for PACE_POC_NRT (PACE_OCI_L3M_POC_NRT)...\n",
      "     ✅ Found 190 granules for PACE_POC_NRT!\n",
      "\n",
      "  -> Searching for MODIS_CHL_V2022 (MODISA_L3M_CHL_2022_4KM)...\n",
      "     ❌ FAILED: Found 0 granules for MODIS_CHL_V2022. Trying next option.\n",
      "\n",
      "  -> Searching for SWOT_SSH (SWOT_L2_LR_SSH_EXPERT_2.0)...\n",
      "     ✅ Found 2438 granules for SWOT_SSH!\n",
      "\n",
      "  -> Searching for SST (MUR-JPL-L4-GLOB-v4.1)...\n",
      "     ✅ Found 1007 granules for SST!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'get': You must call earthaccess.login() before you can download data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Initiating bulk download of 3825 total files...\n",
      "\n",
      "✅ FINAL DOWNLOAD COMPLETE! All available data saved to 'nasa_shark_data_recovery_final'.\n"
     ]
    }
   ],
   "source": [
    "import earthaccess\n",
    "import os\n",
    "import time\n",
    "\n",
    "# --- DEFINE PARAMETERS (Re-use your existing correct values) ---\n",
    "START_DATE = \"2023-01-01T00:00:00Z\"\n",
    "END_DATE = \"2025-12-31T23:59:59Z\"\n",
    "BOUNDING_BOX = (-85.0, 20.0, -50.0, 45.0) \n",
    "DOWNLOAD_DIR = \"nasa_shark_data_recovery_final\" # New directory for the final attempt\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# --- RECOVERY DATA COLLECTIONS ---\n",
    "# Using the specific short names from the last attempt (they were likely correct)\n",
    "RECOVERY_COLLECTIONS = {\n",
    "    \"PACE_CHL_NRT\": \"PACE_OCI_L3M_CHL_NRT\",\n",
    "    \"PACE_POC_NRT\": \"PACE_OCI_L3M_POC_NRT\", \n",
    "    \"MODIS_CHL_V2022\": \"MODISA_L3M_CHL_2022_4KM\",\n",
    "}\n",
    "\n",
    "# --- Successful Collections (to ensure you redownload these) ---\n",
    "SUCCESSFUL_COLLECTIONS = {\n",
    "    \"SWOT_SSH\": \"SWOT_L2_LR_SSH_EXPERT_2.0\",\n",
    "    \"SST\": \"MUR-JPL-L4-GLOB-v4.1\"\n",
    "}\n",
    "\n",
    "# Combine all collections for a comprehensive search\n",
    "ALL_COLLECTIONS = {**RECOVERY_COLLECTIONS, **SUCCESSFUL_COLLECTIONS}\n",
    "\n",
    "\n",
    "# --- 2. Final Comprehensive Search and Download ---\n",
    "\n",
    "print(\"Step 2: Performing Comprehensive Data Search (Excluding 'keywords' argument)...\")\n",
    "\n",
    "all_results = []\n",
    "for mission_name, short_name in ALL_COLLECTIONS.items():\n",
    "    print(f\"\\n  -> Searching for {mission_name} ({short_name})...\")\n",
    "\n",
    "    try:\n",
    "        results = earthaccess.search_data(\n",
    "            short_name=short_name,\n",
    "            temporal=(START_DATE, END_DATE),\n",
    "            bounding_box=BOUNDING_BOX,\n",
    "            # *** KEY FIX: REMOVED 'keywords=keywords' ARGUMENT ***\n",
    "            cloud_hosted=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        # Catch any new unexpected errors\n",
    "        print(f\"     ⚠️ ERROR during search (Check short name/AOI): {e}\")\n",
    "        results = []\n",
    "    \n",
    "    \n",
    "    if results:\n",
    "        print(f\"     ✅ Found {len(results)} granules for {mission_name}!\")\n",
    "        all_results.extend(results)\n",
    "    else:\n",
    "        print(f\"     ❌ FAILED: Found 0 granules for {mission_name}. Trying next option.\")\n",
    "    \n",
    "    time.sleep(1) \n",
    "\n",
    "\n",
    "print(f\"\\nStep 3: Initiating bulk download of {len(all_results)} total files...\")\n",
    "if all_results:\n",
    "    # This downloads all files, including the re-found SWOT/SST data\n",
    "    earthaccess.download(all_results, DOWNLOAD_DIR)\n",
    "    print(f\"\\n✅ FINAL DOWNLOAD COMPLETE! All available data saved to '{DOWNLOAD_DIR}'.\")\n",
    "else:\n",
    "    print(\"❌ No data found with the current parameters. Download skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6420104-e117-4e6b-88ba-7f6eeacc95d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import os\n",
    "import time\n",
    "\n",
    "# --- DEFINE PARAMETERS ---\n",
    "START_DATE = \"2023-01-01T00:00:00Z\"\n",
    "END_DATE = \"2025-12-31T23:59:59Z\"\n",
    "BOUNDING_BOX = (-85.0, 20.0, -50.0, 45.0) \n",
    "\n",
    "# *** CRITICAL FIX: Use an absolute path on a known, spacious drive ***\n",
    "DOWNLOAD_DIR = r\"D:\\NASA_SHARK_PROJECT\\nasa_shark_data_final\" # <-- MODIFY THIS PATH!\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "# ... rest of the code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc4364-8569-4b72-8663-e8f26aa4f8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Performing Comprehensive Data Search (Rerunning all missions)...\n",
      "\n",
      "  -> Searching for PACE_CHL_NRT (PACE_OCI_L3M_CHL_NRT)...\n",
      "     ⚠️ ERROR during search: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "     ❌ FAILED: Found 0 granules for PACE_CHL_NRT.\n",
      "\n",
      "  -> Searching for PACE_POC_NRT (PACE_OCI_L3M_POC_NRT)...\n",
      "     ⚠️ ERROR during search: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "     ❌ FAILED: Found 0 granules for PACE_POC_NRT.\n",
      "\n",
      "  -> Searching for MODIS_CHL_V2022 (MODISA_L3M_CHL_2022_4KM)...\n",
      "     ⚠️ ERROR during search: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "     ❌ FAILED: Found 0 granules for MODIS_CHL_V2022.\n",
      "\n",
      "  -> Searching for SWOT_SSH (SWOT_L2_LR_SSH_EXPERT_2.0)...\n"
     ]
    }
   ],
   "source": [
    "import earthaccess\n",
    "import os\n",
    "import time\n",
    "\n",
    "# --- DEFINE PARAMETERS (Re-use your existing correct values) ---\n",
    "START_DATE = \"2023-01-01T00:00:00Z\"\n",
    "END_DATE = \"2025-12-31T23:59:59Z\"\n",
    "BOUNDING_BOX = (-85.0, 20.0, -50.0, 45.0) \n",
    "\n",
    "# *** CRITICAL FIX: Update the DOWNLOAD_DIR to a safe, spacious drive ***\n",
    "# EXAMPLE: REPLACE \"D:\\Your_Big_Drive\" with your actual path!\n",
    "DOWNLOAD_DIR = r\"D:\\Your_Big_Drive\\nasa_shark_data_final\" \n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- RECOVERY DATA COLLECTIONS ---\n",
    "# We use the list that includes your previous successful and fixed-name collections.\n",
    "ALL_COLLECTIONS = {\n",
    "    # PACE (Hoping for recent data availability)\n",
    "    \"PACE_CHL_NRT\": \"PACE_OCI_L3M_CHL_NRT\",\n",
    "    \"PACE_POC_NRT\": \"PACE_OCI_L3M_POC_NRT\", \n",
    "    \n",
    "    # MODIS (Using the robust version short name)\n",
    "    \"MODIS_CHL_V2022\": \"MODISA_L3M_CHL_2022_4KM\",\n",
    "\n",
    "    # Successful Collections (SWOT and SST)\n",
    "    \"SWOT_SSH\": \"SWOT_L2_LR_SSH_EXPERT_2.0\",\n",
    "    \"SST\": \"MUR-JPL-L4-GLOB-v4.1\"\n",
    "}\n",
    "\n",
    "\n",
    "# --- 3. Final Comprehensive Search and Download ---\n",
    "\n",
    "print(\"Step 2: Performing Comprehensive Data Search (Rerunning all missions)...\")\n",
    "\n",
    "all_results = []\n",
    "successful_downloads = 0\n",
    "\n",
    "for mission_name, short_name in ALL_COLLECTIONS.items():\n",
    "    print(f\"\\n  -> Searching for {mission_name} ({short_name})...\")\n",
    "    \n",
    "    # Search without the rejected 'keywords' argument\n",
    "    try:\n",
    "        results = earthaccess.search_data(\n",
    "            short_name=short_name,\n",
    "            temporal=(START_DATE, END_DATE),\n",
    "            bounding_box=BOUNDING_BOX,\n",
    "            cloud_hosted=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"     ⚠️ ERROR during search: {e}\")\n",
    "        results = []\n",
    "    \n",
    "    if results:\n",
    "        print(f\"     ✅ Found {len(results)} granules for {mission_name}!\")\n",
    "        all_results.extend(results)\n",
    "    else:\n",
    "        print(f\"     ❌ FAILED: Found 0 granules for {mission_name}.\")\n",
    "    \n",
    "    time.sleep(1) \n",
    "\n",
    "\n",
    "print(f\"\\nStep 3: Initiating bulk download of {len(all_results)} total files to '{DOWNLOAD_DIR}'...\")\n",
    "if all_results:\n",
    "    # This will now download to the new location on your large drive\n",
    "    earthaccess.download(all_results, DOWNLOAD_DIR)\n",
    "    print(f\"\\n✅ FINAL DOWNLOAD COMPLETE! All available data saved successfully.\")\n",
    "else:\n",
    "    print(\"❌ No data found with the current parameters. Download skipped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sharkenv)",
   "language": "python",
   "name": "sharkenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
