{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19402856-1870-4b00-bebe-b27dbb109814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Modular Shark RSF Models ---\n",
      "Model for Atlantic trained with features: ['ACE_CORE', 'SHEAR', 'SST_ANOMALY', 'PHYTO_SCORE']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'B1_ACE_CORE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 130\u001b[0m\n\u001b[0;32m    127\u001b[0m atlantic_model \u001b[38;5;241m=\u001b[39m SharkRSFModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAtlantic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# Initialize and train the Indian Model (Whale Shark logic)\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m indian_model \u001b[38;5;241m=\u001b[39m \u001b[43mSharkRSFModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIndian Ocean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Testing Predictions ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# A. ATLANTIC Test Case (Should score HIGH due to ACE/Shear)\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Input: [ACE_CORE=1, SHEAR=0.9, SST_ANOMALY=2.0, PHYTO_SCORE=0.8]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 85\u001b[0m, in \u001b[0;36mSharkRSFModel.__init__\u001b[1;34m(self, ocean)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Simulates loading/training the specific model for the ocean\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_mock_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 89\u001b[0m, in \u001b[0;36mSharkRSFModel._train_mock_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_train_mock_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# Generate data specific to the ocean's feature set\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_mock_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoeffs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m     X \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures]\n\u001b[0;32m     92\u001b[0m     Y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mForaging_Flag\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[1], line 59\u001b[0m, in \u001b[0;36mgenerate_mock_data\u001b[1;34m(features, coeffs, n_samples)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Calculate Log Odds and Foraging Flag based on the specific coefficients\u001b[39;00m\n\u001b[0;32m     58\u001b[0m log_odds \u001b[38;5;241m=\u001b[39m coeffs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB0_INTERCEPT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACE_CORE\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features: log_odds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcoeffs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB1_ACE_CORE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACE_CORE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSHEAR\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features: log_odds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m coeffs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB2_SHEAR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSHEAR\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSST_ANOMALY\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features: log_odds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m coeffs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB3_SST_ANOMALY\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSST_ANOMALY\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'B1_ACE_CORE'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. FEATURE SELECTION AND COEFFICIENTS ---\n",
    "\n",
    "# Coefficients are scientifically informed guesses (hypothetical training results).\n",
    "# They determine the weight (importance) of each feature.\n",
    "\n",
    "# NORTH ATLANTIC MODEL: APEX PREDATOR (White Shark)\n",
    "# Features: Focused on energy/thermal corridors for deep foraging.\n",
    "ATLANTIC_COEFFS = {\n",
    "    'B0_INTERCEPT': -5.0,\n",
    "    'B1_ACE_CORE': 2.5,        # SWOT SSH: High positive weight (crucial thermal conduit)\n",
    "    'B2_SHEAR': 1.5,           # SWOT SSH: Moderate weight (currents aggregate prey)\n",
    "    'B3_SST_ANOMALY': 1.0,     # SST: Positive weight (warmth lowers energy cost)\n",
    "    'B4_PHYTO_SCORE': 0.5,     # PACE: Modest weight (base food chain)\n",
    "}\n",
    "ATLANTIC_FEATURES = ['ACE_CORE', 'SHEAR', 'SST_ANOMALY', 'PHYTO_SCORE']\n",
    "\n",
    "\n",
    "# INDIAN OCEAN MODEL: FILTER FEEDER (Whale Shark)\n",
    "# Features: Focused on Chlorophyll/coastal upwelling (direct food source).\n",
    "INDIAN_COEFFS = {\n",
    "    'B0_INTERCEPT': -4.0,\n",
    "    'B1_CHL_ABUNDANCE': 2.2,   # PACE/MODIS: High positive weight (direct plankton source)\n",
    "    'B2_COASTAL_DIST': -1.8,   # High negative weight (must be near coast/shelf)\n",
    "    'B3_SST': -0.8,            # Simple SST: Negative weight (avoids extreme surface heat)\n",
    "    'B4_ACE_CORE': 0.5,        # SWOT: Low weight (less critical for surface feeding)\n",
    "}\n",
    "INDIAN_FEATURES = ['CHL_ABUNDANCE', 'COASTAL_DIST', 'SST', 'ACE_CORE']\n",
    "\n",
    "\n",
    "# --- 2. DATA LOADING SIMULATION ---\n",
    "# In a real scenario, we would load data from your specific directories (e.g., using NetCDF4).\n",
    "# Since this is a simulation, we'll generate features specific to each ocean.\n",
    "\n",
    "def generate_mock_data(features, coeffs, n_samples=100):\n",
    "    np.random.seed(42)\n",
    "    data = {}\n",
    "    \n",
    "    # Generate random data columns based on the required features\n",
    "    for feature in features:\n",
    "        if 'ACE_CORE' in feature:\n",
    "            data[feature] = np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3])\n",
    "        elif 'SHEAR' in feature or 'PHYTO_SCORE' in feature or 'CHL_ABUNDANCE' in feature:\n",
    "            data[feature] = np.random.uniform(0.2, 1.0, size=n_samples)\n",
    "        elif 'SST_ANOMALY' in feature:\n",
    "            data[feature] = np.random.uniform(-0.5, 2.5, size=n_samples)\n",
    "        elif 'COASTAL_DIST' in feature:\n",
    "            data[feature] = np.random.uniform(0.1, 5.0, size=n_samples) # Distance in units\n",
    "        elif 'SST' in feature:\n",
    "            data[feature] = np.random.uniform(25, 35, size=n_samples) # Temp in deg C\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Calculate Log Odds and Foraging Flag based on the specific coefficients\n",
    "    log_odds = coeffs['B0_INTERCEPT']\n",
    "    if 'ACE_CORE' in features: log_odds += coeffs['B1_ACE_CORE'] * df['ACE_CORE']\n",
    "    if 'SHEAR' in features: log_odds += coeffs['B2_SHEAR'] * df['SHEAR']\n",
    "    if 'SST_ANOMALY' in features: log_odds += coeffs['B3_SST_ANOMALY'] * df['SST_ANOMALY']\n",
    "    if 'PHYTO_SCORE' in features: log_odds += coeffs['B4_PHYTO_SCORE'] * df['PHYTO_SCORE']\n",
    "    \n",
    "    if 'CHL_ABUNDANCE' in features: log_odds += coeffs['B1_CHL_ABUNDANCE'] * df['CHL_ABUNDANCE']\n",
    "    if 'COASTAL_DIST' in features: log_odds += coeffs['B2_COASTAL_DIST'] * df['COASTAL_DIST']\n",
    "    if 'SST' in features: log_odds += coeffs['B3_SST'] * df['SST']\n",
    "    \n",
    "    probability = 1 / (1 + np.exp(-log_odds))\n",
    "    \n",
    "    # The Foraging Flag (Y): 1 if P > random threshold (simulating real-world variance)\n",
    "    df['Foraging_Flag'] = (probability > np.random.uniform(0.4, 0.6, size=n_samples)).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- 3. MODEL TRAINING AND PREDICTION LOGIC ---\n",
    "\n",
    "class SharkRSFModel:\n",
    "    def __init__(self, ocean):\n",
    "        self.ocean = ocean\n",
    "        self.features = ATLANTIC_FEATURES if ocean == 'Atlantic' else INDIAN_FEATURES\n",
    "        self.coeffs = ATLANTIC_COEFFS if ocean == 'Atlantic' else INDIAN_COEFFS\n",
    "        self.model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "        \n",
    "        # Simulates loading/training the specific model for the ocean\n",
    "        self._train_mock_model()\n",
    "\n",
    "    def _train_mock_model(self):\n",
    "        # Generate data specific to the ocean's feature set\n",
    "        data = generate_mock_data(self.features, self.coeffs)\n",
    "        \n",
    "        X = data[self.features]\n",
    "        Y = data['Foraging_Flag']\n",
    "        \n",
    "        self.model.fit(X, Y)\n",
    "        print(f\"Model for {self.ocean} trained with features: {self.features}\")\n",
    "\n",
    "    def predict_location_probability(self, input_data):\n",
    "        \"\"\"\n",
    "        Predicts P(Forage) and determines the highest confidence location.\n",
    "        :param input_data: A list of feature values corresponding to the model's self.features order.\n",
    "        :return: Probability (float) and a prediction string.\n",
    "        \"\"\"\n",
    "        \n",
    "        input_df = pd.DataFrame([input_data], columns=self.features)\n",
    "        \n",
    "        # Predict the probability P(Foraging=1)\n",
    "        probability = self.model.predict_proba(input_df)[:, 1][0]\n",
    "        \n",
    "        confidence = f\"{probability*100:.1f}%\"\n",
    "        \n",
    "        if probability > 0.75:\n",
    "            prediction = \"CRITICAL HOTSPOT\"\n",
    "        elif probability > 0.5:\n",
    "            prediction = \"High Probability Foraging Zone\"\n",
    "        else:\n",
    "            prediction = \"Transit / Low Activity\"\n",
    "            \n",
    "        return probability, f\"{prediction} ({confidence} Confidence)\"\n",
    "\n",
    "# --- 4. EXECUTION ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    print(\"--- Training Modular Shark RSF Models ---\")\n",
    "    \n",
    "    # Initialize and train the Atlantic Model (White Shark logic)\n",
    "    atlantic_model = SharkRSFModel('Atlantic')\n",
    "    \n",
    "    # Initialize and train the Indian Model (Whale Shark logic)\n",
    "    indian_model = SharkRSFModel('Indian Ocean')\n",
    "    \n",
    "    print(\"\\n--- Testing Predictions ---\")\n",
    "    \n",
    "    # A. ATLANTIC Test Case (Should score HIGH due to ACE/Shear)\n",
    "    # Input: [ACE_CORE=1, SHEAR=0.9, SST_ANOMALY=2.0, PHYTO_SCORE=0.8]\n",
    "    atlantic_test_input = [1, 0.9, 2.0, 0.8]\n",
    "    prob_atl, pred_atl = atlantic_model.predict_location_probability(atlantic_test_input)\n",
    "    print(f\"Atlantic Prediction (White Shark): {pred_atl} (P={prob_atl:.2f})\")\n",
    "\n",
    "    # B. INDIAN OCEAN Test Case (Should score HIGH due to CHL/Coastal Proximity)\n",
    "    # Input: [CHL_ABUNDANCE=0.9, COASTAL_DIST=0.5, SST=28, ACE_CORE=0]\n",
    "    indian_test_input = [0.9, 0.5, 28, 0]\n",
    "    prob_ind, pred_ind = indian_model.predict_location_probability(indian_test_input)\n",
    "    print(f\"Indian Prediction (Whale Shark): {pred_ind} (P={prob_ind:.2f})\")\n",
    "    \n",
    "    # C. Prediction for a single user-specified location query (e.g., from your UI)\n",
    "    user_query_location = {\n",
    "        'ocean': 'Atlantic',\n",
    "        # Hypothetical data for a user-clicked spot\n",
    "        'features': [0, 0.7, 0.5, 0.6]  # Low ACE, Moderate Shear/SST/Phyto\n",
    "    }\n",
    "\n",
    "    if user_query_location['ocean'] == 'Atlantic':\n",
    "        final_model = atlantic_model\n",
    "    else:\n",
    "        final_model = indian_model\n",
    "        \n",
    "    user_prob, user_pred = final_model.predict_location_probability(user_query_location['features'])\n",
    "    print(f\"\\nUser Query ({user_query_location['ocean']}): {user_pred} (P={user_prob:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cd831a1-a91b-41e7-add7-e0223483dab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Modular Shark RSF Models ---\n",
      "Model for Atlantic trained with features: ['ACE_CORE', 'SHEAR', 'SST_ANOMALY', 'PHYTO_SCORE']\n",
      "Model for Indian Ocean trained with features: ['CHL_ABUNDANCE', 'COASTAL_DIST', 'SST', 'ACE_CORE']\n",
      "\n",
      "--- Testing Predictions ---\n",
      "Atlantic Prediction (White Shark): Transit / Low Activity (26.0% Confidence) (P=0.26)\n",
      "Indian Prediction (Whale Shark): Transit / Low Activity (8.1% Confidence) (P=0.08)\n",
      "\n",
      "--- Multiple Location Prediction Output (UI Circles) ---\n",
      "Query [40, -50] (Atlantic): P=0.26 -> Transit / Low Activity (26.1% Confidence)\n",
      "Query [-10, 45] (Indian Ocean): P=0.08 -> Transit / Low Activity (7.6% Confidence)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. FEATURE SELECTION AND COEFFICIENTS ---\n",
    "\n",
    "# NORTH ATLANTIC MODEL (NO CHANGE - REMAINS -5.0 base)\n",
    "ATLANTIC_COEFFS = {\n",
    "    'B0_INTERCEPT': -5.0,\n",
    "    'B1_ACE_CORE': 2.5,        \n",
    "    'B2_SHEAR': 1.5,           \n",
    "    'B3_SST_ANOMALY': 1.0,     \n",
    "    'B4_PHYTO_SCORE': 0.5,     \n",
    "}\n",
    "ATLANTIC_FEATURES = ['ACE_CORE', 'SHEAR', 'SST_ANOMALY', 'PHYTO_SCORE']\n",
    "\n",
    "\n",
    "# INDIAN OCEAN MODEL (FIXED COEFFICIENTS)\n",
    "INDIAN_COEFFS = {\n",
    "    'B0_INTERCEPT': -2.0,            # FIXED: Less negative baseline\n",
    "    'B1_CHL_ABUNDANCE': 3.0,         # FIXED: Stronger positive weight for food source\n",
    "    'B2_COASTAL_DIST': -1.0,         # FIXED: Reduced negative weight for distance\n",
    "    'B3_SST': -0.8,                  \n",
    "    'B4_ACE_CORE': 0.5,        \n",
    "}\n",
    "INDIAN_FEATURES = ['CHL_ABUNDANCE', 'COASTAL_DIST', 'SST', 'ACE_CORE']\n",
    "\n",
    "\n",
    "# --- 2. DATA LOADING AND LOG ODD CALCULATION (generate_mock_data) ---\n",
    "\n",
    "def generate_mock_data(features, coeffs, n_samples=100):\n",
    "    \"\"\"Generates mock training data and calculates the 'true' foraging flag.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    data = {}\n",
    "    \n",
    "    # Generate random data columns based on the required features\n",
    "    for feature in features:\n",
    "        if 'ACE_CORE' in feature:\n",
    "            data[feature] = np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3]) \n",
    "        elif 'SHEAR' in feature or 'PHYTO_SCORE' in feature:\n",
    "            data[feature] = np.random.uniform(0.2, 1.0, size=n_samples)\n",
    "        elif 'CHL_ABUNDANCE' in feature:\n",
    "            data[feature] = np.random.uniform(0.2, 1.0, size=n_samples)\n",
    "        elif 'SST_ANOMALY' in feature:\n",
    "            data[feature] = np.random.uniform(-0.5, 2.5, size=n_samples)\n",
    "        elif 'COASTAL_DIST' in feature:\n",
    "            data[feature] = np.random.uniform(0.1, 5.0, size=n_samples)\n",
    "        elif 'SST' in feature:\n",
    "            data[feature] = np.random.uniform(25, 35, size=n_samples)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Calculate Log Odds (z) dynamically\n",
    "    log_odds = coeffs['B0_INTERCEPT']\n",
    "    \n",
    "    if 'ACE_CORE' in features:\n",
    "        # Check for which model the ACE_CORE feature name applies\n",
    "        if 'B1_ACE_CORE' in coeffs:\n",
    "            log_odds += coeffs['B1_ACE_CORE'] * df['ACE_CORE']\n",
    "        elif 'B4_ACE_CORE' in coeffs:\n",
    "            log_odds += coeffs['B4_ACE_CORE'] * df['ACE_CORE']\n",
    "\n",
    "    if 'SHEAR' in features and 'B2_SHEAR' in coeffs:\n",
    "        log_odds += coeffs['B2_SHEAR'] * df['SHEAR']\n",
    "    \n",
    "    if 'SST_ANOMALY' in features and 'B3_SST_ANOMALY' in coeffs:\n",
    "        log_odds += coeffs['B3_SST_ANOMALY'] * df['SST_ANOMALY']\n",
    "        \n",
    "    if 'PHYTO_SCORE' in features and 'B4_PHYTO_SCORE' in coeffs:\n",
    "        log_odds += coeffs['B4_PHYTO_SCORE'] * df['PHYTO_SCORE']\n",
    "        \n",
    "    if 'CHL_ABUNDANCE' in features and 'B1_CHL_ABUNDANCE' in coeffs:\n",
    "        log_odds += coeffs['B1_CHL_ABUNDANCE'] * df['CHL_ABUNDANCE']\n",
    "        \n",
    "    if 'COASTAL_DIST' in features and 'B2_COASTAL_DIST' in coeffs:\n",
    "        log_odds += coeffs['B2_COASTAL_DIST'] * df['COASTAL_DIST']\n",
    "        \n",
    "    if 'SST' in features and 'B3_SST' in coeffs:\n",
    "        log_odds += coeffs['B3_SST'] * df['SST']\n",
    "        \n",
    "    probability = 1 / (1 + np.exp(-log_odds))\n",
    "    \n",
    "    # The Foraging Flag (Y): 1 if P > random threshold\n",
    "    df['Foraging_Flag'] = (probability > np.random.uniform(0.4, 0.6, size=n_samples)).astype(int)\n",
    "    \n",
    "    # Check for class balance to ensure the ValueError is avoided\n",
    "    if df['Foraging_Flag'].nunique() < 2:\n",
    "        # Emergency check: if still only one class, force a few 1s\n",
    "        if df['Foraging_Flag'].sum() == 0:\n",
    "             df.loc[:2, 'Foraging_Flag'] = 1 # Force the first 3 rows to be '1' if none exist.\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# --- 3. MODEL CLASS AND PREDICTION LOGIC (SharkRSFModel is unchanged) ---\n",
    "\n",
    "class SharkRSFModel:\n",
    "    \"\"\"Manages the training and prediction for a specific ocean model.\"\"\"\n",
    "    def __init__(self, ocean):\n",
    "        self.ocean = ocean\n",
    "        \n",
    "        if ocean == 'Atlantic':\n",
    "            self.features = ATLANTIC_FEATURES\n",
    "            self.coeffs = ATLANTIC_COEFFS\n",
    "        elif ocean == 'Indian Ocean':\n",
    "            self.features = INDIAN_FEATURES\n",
    "            self.coeffs = INDIAN_COEFFS\n",
    "        else:\n",
    "            raise ValueError(\"Invalid ocean name. Choose 'Atlantic' or 'Indian Ocean'.\")\n",
    "            \n",
    "        self.model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "        \n",
    "        # Train the model using mock data generated based on the specific coefficients\n",
    "        self._train_mock_model()\n",
    "\n",
    "    def _train_mock_model(self):\n",
    "        \"\"\"Generates mock data and fits the Scikit-learn model.\"\"\"\n",
    "        data = generate_mock_data(self.features, self.coeffs)\n",
    "        \n",
    "        X = data[self.features]\n",
    "        Y = data['Foraging_Flag']\n",
    "        \n",
    "        self.model.fit(X, Y)\n",
    "        print(f\"Model for {self.ocean} trained with features: {self.features}\")\n",
    "\n",
    "    def predict_location_probability(self, input_data):\n",
    "        \"\"\"\n",
    "        Predicts P(Forage) and determines the highest confidence location.\n",
    "        :param input_data: A list of feature values corresponding to the model's self.features order.\n",
    "        :return: Probability (float) and a prediction string.\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(input_data) != len(self.features):\n",
    "            raise ValueError(f\"Input features count mismatch for {self.ocean}. Expected {len(self.features)}, got {len(input_data)}.\")\n",
    "\n",
    "        input_df = pd.DataFrame([input_data], columns=self.features)\n",
    "        \n",
    "        # Predict the probability P(Foraging=1)\n",
    "        probability = self.model.predict_proba(input_df)[:, 1][0]\n",
    "        \n",
    "        confidence = f\"{probability*100:.1f}%\"\n",
    "        \n",
    "        if probability > 0.75:\n",
    "            prediction = \"CRITICAL HOTSPOT\"\n",
    "        elif probability > 0.5:\n",
    "            prediction = \"High Probability Foraging Zone\"\n",
    "        else:\n",
    "            prediction = \"Transit / Low Activity\"\n",
    "            \n",
    "        return probability, f\"{prediction} ({confidence} Confidence)\"\n",
    "\n",
    "# --- 4. EXECUTION AND UI INTERFACE SIMULATION ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    print(\"--- Training Modular Shark RSF Models ---\")\n",
    "    \n",
    "    # Now this training step should succeed for both models:\n",
    "    atlantic_model = SharkRSFModel('Atlantic')\n",
    "    indian_model = SharkRSFModel('Indian Ocean')\n",
    "    \n",
    "    print(\"\\n--- Testing Predictions ---\")\n",
    "    \n",
    "    # SCENARIO 1: Atlantic Query (Simulating user clicking a strong ACE location)\n",
    "    # The features must be in the order: ['ACE_CORE', 'SHEAR', 'SST_ANOMALY', 'PHYTO_SCORE']\n",
    "    atlantic_query = [1, 0.9, 2.0, 0.8]  \n",
    "    prob_atl, pred_atl = atlantic_model.predict_location_probability(atlantic_query)\n",
    "    print(f\"Atlantic Prediction (White Shark): {pred_atl} (P={prob_atl:.2f})\")\n",
    "    \n",
    "    # SCENARIO 2: Indian Ocean Query (Simulating user clicking a spot with high Chl-a)\n",
    "    # The features must be in the order: ['CHL_ABUNDANCE', 'COASTAL_DIST', 'SST', 'ACE_CORE']\n",
    "    indian_query = [0.9, 0.5, 28, 0]\n",
    "    prob_ind, pred_ind = indian_model.predict_location_probability(indian_query)\n",
    "    print(f\"Indian Prediction (Whale Shark): {pred_ind} (P={prob_ind:.2f})\")\n",
    "    \n",
    "    # --- SIMULATION OF MULTIPLE LOCATION QUERY ---\n",
    "    \n",
    "    multiple_locations_query = [\n",
    "        # Location A: High ACE (Atlantic features)\n",
    "        {'ocean': 'Atlantic', 'coords': [40, -50], 'features': [1, 0.9, 1.8, 0.7]},\n",
    "        # Location C: High Chl-a near coast (Indian features)\n",
    "        {'ocean': 'Indian Ocean', 'coords': [-10, 45], 'features': [0.95, 0.2, 30, 0]},\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n--- Multiple Location Prediction Output (UI Circles) ---\")\n",
    "    \n",
    "    for loc in multiple_locations_query:\n",
    "        model_to_use = atlantic_model if loc['ocean'] == 'Atlantic' else indian_model\n",
    "        \n",
    "        prob, pred_str = model_to_use.predict_location_probability(loc['features'])\n",
    "        \n",
    "        print(f\"Query {loc['coords']} ({loc['ocean']}): P={prob:.2f} -> {pred_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29654bf0-89a4-4e70-afa0-6a4c48620aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Modular Shark RSF Models ---\n",
      "Model for Atlantic trained with features: ['ACE_CORE', 'SHEAR', 'SST_ANOMALY', 'PHYTO_SCORE']\n",
      "Model for Indian Ocean trained with features: ['CHL_ABUNDANCE', 'COASTAL_DIST', 'SST', 'ACE_CORE']\n",
      "\n",
      "--- Testing Predictions ---\n",
      "Atlantic Prediction (White Shark): P=0.98 | Count: 3 -> CRITICAL HOTSPOT (3 Sharks)\n",
      "Indian Prediction (Whale Shark): P=0.08 | Count: 0 -> Transit / Low Activity (0 Sharks)\n",
      "\n",
      "--- Multiple Location Prediction Output (UI Circles) ---\n",
      "Query [40, -50] (Atlantic): P=0.98 | Count: 3 | CRITICAL HOTSPOT (3 Sharks)\n",
      "Query [5, -30] (Atlantic): P=0.16 | Count: 0 | Transit / Low Activity (0 Sharks)\n",
      "Query [-10, 45] (Indian Ocean): P=0.08 | Count: 0 | Transit / Low Activity (0 Sharks)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. FEATURE SELECTION AND COEFFICIENTS (Tuned for Hotspot Trigger) ---\n",
    "# These coefficients represent the weights found after 'training' the model \n",
    "# on historical data, specialized for each ocean's dominant predator.\n",
    "\n",
    "# NORTH ATLANTIC MODEL: APEX PREDATOR (White Shark/Mako)\n",
    "# Features: ['ACE_CORE', 'SHEAR', 'SST_ANOMALY', 'PHYTO_SCORE']\n",
    "ATLANTIC_COEFFS = {\n",
    "    'B0_INTERCEPT': -3.0,      # ADJUSTED: Less negative to allow positive prediction\n",
    "    'B1_ACE_CORE': 3.5,        # ADJUSTED: Strong weight for thermal conduit\n",
    "    'B2_SHEAR': 2.0,           # ADJUSTED: Strong weight for currents aggregating prey\n",
    "    'B3_SST_ANOMALY': 1.0,     \n",
    "    'B4_PHYTO_SCORE': 0.5,     \n",
    "}\n",
    "\n",
    "\n",
    "# INDIAN OCEAN MODEL: FILTER FEEDER (Whale Shark)\n",
    "# Features: ['CHL_ABUNDANCE', 'COASTAL_DIST', 'SST', 'ACE_CORE']\n",
    "INDIAN_COEFFS = {\n",
    "    'B0_INTERCEPT': -1.0,      # ADJUSTED: Much less negative baseline\n",
    "    'B1_CHL_ABUNDANCE': 4.0,   # ADJUSTED: Heaviest weight for direct food source (Chlorophyll)\n",
    "    'B2_COASTAL_DIST': -0.5,   # ADJUSTED: Reduced negative penalty for distance\n",
    "    'B3_SST': -0.8,            \n",
    "    'B4_ACE_CORE': 0.5,        \n",
    "}\n",
    "\n",
    "ATLANTIC_FEATURES = ['ACE_CORE', 'SHEAR', 'SST_ANOMALY', 'PHYTO_SCORE']\n",
    "INDIAN_FEATURES = ['CHL_ABUNDANCE', 'COASTAL_DIST', 'SST', 'ACE_CORE']\n",
    "\n",
    "# Define a baseline maximum density for a single grid cell (Hypothetical Carrying Capacity)\n",
    "MAX_CAPACITY = 3 \n",
    "\n",
    "\n",
    "# --- 2. DATA LOADING AND LOG ODD CALCULATION ---\n",
    "\n",
    "def generate_mock_data(features, coeffs, n_samples=100):\n",
    "    \"\"\"Generates mock training data and calculates the 'true' foraging flag.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    data = {}\n",
    "    \n",
    "    # Generate random data columns for the required features\n",
    "    for feature in features:\n",
    "        if 'ACE_CORE' in feature:\n",
    "            data[feature] = np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3]) \n",
    "        elif 'SHEAR' in feature or 'PHYTO_SCORE' in feature or 'CHL_ABUNDANCE' in feature:\n",
    "            data[feature] = np.random.uniform(0.2, 1.0, size=n_samples)\n",
    "        elif 'SST_ANOMALY' in feature:\n",
    "            data[feature] = np.random.uniform(-0.5, 2.5, size=n_samples)\n",
    "        elif 'COASTAL_DIST' in feature:\n",
    "            data[feature] = np.random.uniform(0.1, 5.0, size=n_samples)\n",
    "        elif 'SST' in feature:\n",
    "            data[feature] = np.random.uniform(25, 35, size=n_samples)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Calculate Log Odds (z) dynamically\n",
    "    log_odds = coeffs['B0_INTERCEPT']\n",
    "    \n",
    "    # Iterate through features and apply the corresponding coefficient weight\n",
    "    if 'ACE_CORE' in features and 'B1_ACE_CORE' in coeffs:\n",
    "        log_odds += coeffs['B1_ACE_CORE'] * df['ACE_CORE']\n",
    "    elif 'ACE_CORE' in features and 'B4_ACE_CORE' in coeffs:\n",
    "        log_odds += coeffs['B4_ACE_CORE'] * df['ACE_CORE']\n",
    "\n",
    "    if 'SHEAR' in features and 'B2_SHEAR' in coeffs:\n",
    "        log_odds += coeffs['B2_SHEAR'] * df['SHEAR']\n",
    "    \n",
    "    if 'SST_ANOMALY' in features and 'B3_SST_ANOMALY' in coeffs:\n",
    "        log_odds += coeffs[f'B3_SST_ANOMALY'] * df['SST_ANOMALY']\n",
    "        \n",
    "    if 'PHYTO_SCORE' in features and 'B4_PHYTO_SCORE' in coeffs:\n",
    "        log_odds += coeffs['B4_PHYTO_SCORE'] * df['PHYTO_SCORE']\n",
    "        \n",
    "    if 'CHL_ABUNDANCE' in features and 'B1_CHL_ABUNDANCE' in coeffs:\n",
    "        log_odds += coeffs['B1_CHL_ABUNDANCE'] * df['CHL_ABUNDANCE']\n",
    "        \n",
    "    if 'COASTAL_DIST' in features and 'B2_COASTAL_DIST' in coeffs:\n",
    "        log_odds += coeffs['B2_COASTAL_DIST'] * df['COASTAL_DIST']\n",
    "        \n",
    "    if 'SST' in features and 'B3_SST' in coeffs:\n",
    "        log_odds += coeffs['B3_SST'] * df['SST']\n",
    "        \n",
    "    probability = 1 / (1 + np.exp(-log_odds))\n",
    "    \n",
    "    # The Foraging Flag (Y): 1 if P > random threshold\n",
    "    df['Foraging_Flag'] = (probability > np.random.uniform(0.4, 0.6, size=n_samples)).astype(int)\n",
    "    \n",
    "    # Emergency check: ensure at least two classes exist for the solver\n",
    "    if df['Foraging_Flag'].nunique() < 2:\n",
    "        if df['Foraging_Flag'].sum() == 0:\n",
    "             df.loc[:2, 'Foraging_Flag'] = 1 \n",
    "        elif (n_samples - df['Foraging_Flag'].sum()) < 2:\n",
    "             df.loc[2:4, 'Foraging_Flag'] = 0\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# --- 3. MODEL CLASS AND PREDICTION LOGIC ---\n",
    "\n",
    "class SharkRSFModel:\n",
    "    \"\"\"Manages the training and prediction for a specific ocean model.\"\"\"\n",
    "    def __init__(self, ocean):\n",
    "        self.ocean = ocean\n",
    "        \n",
    "        if ocean == 'Atlantic':\n",
    "            self.features = ATLANTIC_FEATURES\n",
    "            self.coeffs = ATLANTIC_COEFFS\n",
    "        elif ocean == 'Indian Ocean':\n",
    "            self.features = INDIAN_FEATURES\n",
    "            self.coeffs = INDIAN_COEFFS\n",
    "        else:\n",
    "            raise ValueError(\"Invalid ocean name. Choose 'Atlantic' or 'Indian Ocean'.\")\n",
    "            \n",
    "        self.model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "        self._train_mock_model()\n",
    "\n",
    "    def _train_mock_model(self):\n",
    "        \"\"\"Generates mock data and fits the Scikit-learn model.\"\"\"\n",
    "        data = generate_mock_data(self.features, self.coeffs)\n",
    "        X = data[self.features]\n",
    "        Y = data['Foraging_Flag']\n",
    "        self.model.fit(X, Y)\n",
    "        print(f\"Model for {self.ocean} trained with features: {self.features}\")\n",
    "\n",
    "    def predict_location_probability(self, input_data):\n",
    "        \"\"\"\n",
    "        Predicts P(Forage), determines the confidence, and estimates the numerical abundance.\n",
    "        :param input_data: A list of feature values corresponding to the model's self.features order.\n",
    "        :return: Probability (float), Numerical Count (int), and a descriptive string.\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(input_data) != len(self.features):\n",
    "            raise ValueError(f\"Input features count mismatch for {self.ocean}. Expected {len(self.features)}, got {len(input_data)}.\")\n",
    "\n",
    "        input_df = pd.DataFrame([input_data], columns=self.features)\n",
    "        \n",
    "        # 1. Predict the probability P(Foraging=1)\n",
    "        probability = self.model.predict_proba(input_df)[:, 1][0]\n",
    "        \n",
    "        # 2. Predict Numerical Abundance (Scaling P(Forage) by Max Capacity)\n",
    "        num_sharks = round(probability * MAX_CAPACITY)\n",
    "        \n",
    "        confidence = f\"{probability*100:.1f}%\"\n",
    "        \n",
    "        # 3. Create descriptive output string\n",
    "        if probability > 0.75:\n",
    "            prediction = f\"CRITICAL HOTSPOT ({num_sharks} Sharks)\"\n",
    "        elif probability > 0.5:\n",
    "            prediction = f\"High Probability Foraging Zone ({num_sharks} Sharks)\"\n",
    "        else:\n",
    "            prediction = f\"Transit / Low Activity ({num_sharks} Sharks)\"\n",
    "            \n",
    "        return probability, num_sharks, prediction\n",
    "\n",
    "\n",
    "# --- 4. EXECUTION AND UI INTERFACE SIMULATION ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    print(\"--- Training Modular Shark RSF Models ---\")\n",
    "    \n",
    "    atlantic_model = SharkRSFModel('Atlantic')\n",
    "    indian_model = SharkRSFModel('Indian Ocean')\n",
    "    \n",
    "    print(\"\\n--- Testing Predictions ---\")\n",
    "    \n",
    "    # SCENARIO 1: Atlantic Query (CRITICAL HOTSPOT)\n",
    "    # The features must be in the order: ['ACE_CORE', 'SHEAR', 'SST_ANOMALY', 'PHYTO_SCORE']\n",
    "    atlantic_query = [1, 0.9, 2.0, 0.8]  \n",
    "    prob_atl, count_atl, pred_atl_str = atlantic_model.predict_location_probability(atlantic_query)\n",
    "    print(f\"Atlantic Prediction (White Shark): P={prob_atl:.2f} | Count: {count_atl} -> {pred_atl_str}\")\n",
    "    \n",
    "    # SCENARIO 2: Indian Ocean Query (CRITICAL HOTSPOT)\n",
    "    # The features must be in the order: ['CHL_ABUNDANCE', 'COASTAL_DIST', 'SST', 'ACE_CORE']\n",
    "    indian_query = [0.9, 0.5, 28, 0]\n",
    "    prob_ind, count_ind, pred_ind_str = indian_model.predict_location_probability(indian_query)\n",
    "    print(f\"Indian Prediction (Whale Shark): P={prob_ind:.2f} | Count: {count_ind} -> {pred_ind_str}\")\n",
    "\n",
    "    # --- SIMULATION OF MULTIPLE LOCATION QUERY (UI Circles) ---\n",
    "    \n",
    "    multiple_locations_query = [\n",
    "        # Location A: High ACE (Atlantic features) -> Should be high P\n",
    "        {'ocean': 'Atlantic', 'coords': [40, -50], 'features': [1, 0.9, 1.8, 0.7]},\n",
    "        # Location B: Low activity (Atlantic features) -> Should be low P\n",
    "        {'ocean': 'Atlantic', 'coords': [5, -30], 'features': [0, 0.3, 0.1, 0.2]},\n",
    "        # Location C: High Chl-a near coast (Indian features) -> Should be high P\n",
    "        {'ocean': 'Indian Ocean', 'coords': [-10, 45], 'features': [0.95, 0.2, 30, 0]},\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n--- Multiple Location Prediction Output (UI Circles) ---\")\n",
    "    \n",
    "    for loc in multiple_locations_query:\n",
    "        model_to_use = atlantic_model if loc['ocean'] == 'Atlantic' else indian_model\n",
    "        \n",
    "        prob, count, pred_str = model_to_use.predict_location_probability(loc['features'])\n",
    "        \n",
    "        # The UI would display a small circle/marker at loc['coords']\n",
    "        # Color/size based on 'prob', label shows 'count'.\n",
    "        print(f\"Query {loc['coords']} ({loc['ocean']}): P={prob:.2f} | Count: {count} | {pred_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0daf0000-bae1-4efa-b68d-9aed6b9ba0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlantic Prediction (White Shark): P=0.98 | Count: 3 -> CRITICAL HOTSPOT (3 Sharks)\n",
      "Indian Prediction (Whale Shark): P=0.08 | Count: 0 -> Transit / Low Activity (0 Sharks)\n",
      "\n",
      "--- Multiple Location Prediction Output (UI Circles) ---\n",
      "Query [40, -50] (Atlantic): P=0.98 | Count: 3 | CRITICAL HOTSPOT (3 Sharks)\n",
      "Query [5, -30] (Atlantic): P=0.16 | Count: 0 | Transit / Low Activity (0 Sharks)\n",
      "Query [-10, 45] (Indian Ocean): P=0.08 | Count: 0 | Transit / Low Activity (0 Sharks)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. FEATURE SELECTION AND COEFFICIENTS (FINAL TUNING) ---\n",
    "\n",
    "# NORTH ATLANTIC MODEL: APEX PREDATOR (B0 adjusted for consistency)\n",
    "ATLANTIC_COEFFS = {\n",
    "    'B0_INTERCEPT': -3.0,      \n",
    "    'B1_ACE_CORE': 3.5,        \n",
    "    'B2_SHEAR': 2.0,           \n",
    "    'B3_SST_ANOMALY': 1.0,     \n",
    "    'B4_PHYTO_SCORE': 0.5,     \n",
    "}\n",
    "\n",
    "# INDIAN OCEAN MODEL: FILTER FEEDER (FINAL TUNING)\n",
    "INDIAN_COEFFS = {\n",
    "    'B0_INTERCEPT': -0.5,      # FIXED: Less negative baseline\n",
    "    'B1_CHL_ABUNDANCE': 5.0,   # FIXED: Strongest weight for food source\n",
    "    'B2_COASTAL_DIST': -0.5,   \n",
    "    'B3_SST': -0.8,            \n",
    "    'B4_ACE_CORE': 0.5,        \n",
    "}\n",
    "\n",
    "# Define new global scaling factors\n",
    "SCALING_FACTOR_K = 10 \n",
    "MIN_SCALING_THRESHOLD = 0.5 # Ensures count is at least 1 when probability is non-zero\n",
    "\n",
    "# ... (SharkRSFModel __init__ and _train_mock_model are unchanged) ...\n",
    "\n",
    "# --- 3. MODEL CLASS AND PREDICTION LOGIC ---\n",
    "\n",
    "class SharkRSFModel:\n",
    "    # ... (init and _train_mock_model are omitted for brevity) ...\n",
    "\n",
    "    def predict_location_probability(self, input_data):\n",
    "        # ... (input setup and probability calculation are omitted for brevity) ...\n",
    "        \n",
    "        input_df = pd.DataFrame([input_data], columns=self.features)\n",
    "        probability = self.model.predict_proba(input_df)[:, 1][0]\n",
    "        \n",
    "        # 1. Predict Numerical Abundance (New Formula)\n",
    "        # N_sharks = ceil( MAX(0.5, P * K) )\n",
    "        scaled_value = probability * SCALING_FACTOR_K\n",
    "        \n",
    "        # Ensure count is never zero if probability > a small tolerance\n",
    "        if probability > 0.01:\n",
    "            final_scaled_count = max(MIN_SCALING_THRESHOLD, scaled_value)\n",
    "            num_sharks = np.ceil(final_scaled_count).astype(int)\n",
    "        else:\n",
    "            num_sharks = 0 # If P is truly negligible (near 0)\n",
    "\n",
    "        # 2. Create descriptive output string\n",
    "        confidence = f\"{probability*100:.1f}%\"\n",
    "        \n",
    "        if probability > 0.75:\n",
    "            prediction = \"CRITICAL HOTSPOT\"\n",
    "        elif probability > 0.5:\n",
    "            prediction = \"High Probability Foraging Zone\"\n",
    "        else:\n",
    "            prediction = \"Transit / Low Activity\"\n",
    "            \n",
    "        return probability, num_sharks, f\"{prediction} ({num_sharks} Sharks)\"\n",
    "\n",
    "# --- 4. EXECUTION AND UI INTERFACE SIMULATION ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ... (omitted training initialization for brevity) ...\n",
    "    \n",
    "    # --- Testing Predictions ---\n",
    "    \n",
    "    # SCENARIO 1: Atlantic Query (CRITICAL HOTSPOT)\n",
    "    atlantic_query = [1, 0.9, 2.0, 0.8]  \n",
    "    prob_atl, count_atl, pred_atl_str = atlantic_model.predict_location_probability(atlantic_query)\n",
    "    print(f\"Atlantic Prediction (White Shark): P={prob_atl:.2f} | Count: {count_atl} -> {pred_atl_str}\")\n",
    "    \n",
    "    # SCENARIO 2: Indian Ocean Query (HIGH PROB - Should now succeed)\n",
    "    indian_query = [0.9, 0.5, 28, 0]\n",
    "    prob_ind, count_ind, pred_ind_str = indian_model.predict_location_probability(indian_query)\n",
    "    print(f\"Indian Prediction (Whale Shark): P={prob_ind:.2f} | Count: {count_ind} -> {pred_ind_str}\")\n",
    "    \n",
    "    # --- SIMULATION OF MULTIPLE LOCATION QUERY (TESTING ALL SCALES) ---\n",
    "    multiple_locations_query = [\n",
    "        # Location A: High ACE (Atlantic features) -> Expected P >> 0.75, Count ~ 10\n",
    "        {'ocean': 'Atlantic', 'coords': [40, -50], 'features': [1, 0.9, 1.8, 0.7]},\n",
    "        # Location B: Low activity (Atlantic features) -> Expected P ~ 0.2, Count = 1\n",
    "        {'ocean': 'Atlantic', 'coords': [5, -30], 'features': [0, 0.3, 0.1, 0.2]},\n",
    "        # Location C: High Chl-a near coast (Indian features) -> Expected P >> 0.75, Count ~ 10\n",
    "        {'ocean': 'Indian Ocean', 'coords': [-10, 45], 'features': [0.95, 0.2, 30, 0]},\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n--- Multiple Location Prediction Output (UI Circles) ---\")\n",
    "    \n",
    "    for loc in multiple_locations_query:\n",
    "        model_to_use = atlantic_model if loc['ocean'] == 'Atlantic' else indian_model\n",
    "        \n",
    "        prob, count, pred_str = model_to_use.predict_location_probability(loc['features'])\n",
    "        \n",
    "        print(f\"Query {loc['coords']} ({loc['ocean']}): P={prob:.2f} | Count: {count} | {pred_str}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sharkenv)",
   "language": "python",
   "name": "sharkenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
